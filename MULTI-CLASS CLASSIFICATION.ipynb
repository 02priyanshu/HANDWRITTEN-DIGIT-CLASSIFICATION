{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1babb69d-7264-42d8-bf18-e34fe52fa89d",
   "metadata": {},
   "source": [
    "MULTI CLASS CLASIFICATION MODEL --- DIGIT[0,1,2,3,4,5,6,7,8,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b5dca4d-cda4-4019-8bd7-6d2a675a55ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers,models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93557040-29af-458f-9424-2b4e02bd373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ffa2817-29ba-4b43-948e-97d0acb05e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder_path):\n",
    "    images=[]\n",
    "    labels=[]\n",
    "    for filename in os.listdir(folder_path):\n",
    "        image_path=os.path.join(folder_path,filename)\n",
    "        image=Image.open(image_path).resize(image_size)\n",
    "        image_array=np.array(image)/255.0\n",
    "        images.append(image_array)\n",
    "        labels.append(int(os.path.basename(folder_path)))\n",
    "    return np.array(images),np.array(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eb4f2a-041d-4dfa-ac6b-6f0458ee1eec",
   "metadata": {},
   "source": [
    "LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52778c43-c127-49f6-8976-8d98b384ea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder1_images, folder1_labels = load_images_from_folder(\"C:\\\\Users\\\\Priyanshul\\\\OneDrive\\\\Desktop\\\\Handwritten\\\\archive\\\\database\\\\0\")\n",
    "folder2_images, folder2_labels = load_images_from_folder(\"C:\\\\Users\\\\Priyanshul\\\\OneDrive\\\\Desktop\\\\Handwritten\\\\archive\\\\database\\\\1\")\n",
    "folder3_images, folder3_labels = load_images_from_folder(\"C:\\\\Users\\\\Priyanshul\\\\OneDrive\\\\Desktop\\\\Handwritten\\\\archive\\\\database\\\\2\")\n",
    "folder4_images, folder4_labels = load_images_from_folder(\"C:\\\\Users\\\\Priyanshul\\\\OneDrive\\\\Desktop\\\\Handwritten\\\\archive\\\\database\\\\3\")\n",
    "folder5_images, folder5_labels = load_images_from_folder(\"C:\\\\Users\\\\Priyanshul\\\\OneDrive\\\\Desktop\\\\Handwritten\\\\archive\\\\database\\\\4\")\n",
    "folder6_images, folder6_labels = load_images_from_folder(\"C:\\\\Users\\\\Priyanshul\\\\OneDrive\\\\Desktop\\\\Handwritten\\\\archive\\\\database\\\\5\")\n",
    "folder7_images, folder7_labels = load_images_from_folder(\"C:\\\\Users\\\\Priyanshul\\\\OneDrive\\\\Desktop\\\\Handwritten\\\\archive\\\\database\\\\6\")\n",
    "folder8_images, folder8_labels = load_images_from_folder(\"C:\\\\Users\\\\Priyanshul\\\\OneDrive\\\\Desktop\\\\Handwritten\\\\archive\\\\database\\\\7\")\n",
    "folder9_images, folder9_labels = load_images_from_folder(\"C:\\\\Users\\\\Priyanshul\\\\OneDrive\\\\Desktop\\\\Handwritten\\\\archive\\\\database\\\\8\")\n",
    "folder10_images, folder10_labels = load_images_from_folder(\"C:\\\\Users\\\\Priyanshul\\\\OneDrive\\\\Desktop\\\\Handwritten\\\\archive\\\\database\\\\9\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ab5d361-7631-4a42-98c5-07e09e88b68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3001, 28, 28, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder1_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13737ee9-82f4-47c3-91c6-109defab5804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3001,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder2_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6b43c5-a5a6-4cb6-aca2-2ef9f80836fc",
   "metadata": {},
   "source": [
    "CREATING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01753e84-4dc9-414e-9b3f-b849e932d3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "images=np.concatenate((folder1_images,folder2_images,folder3_images,folder4_images,folder5_images,folder6_images,folder7_images,folder8_images,folder9_images,folder10_images),axis=0)\n",
    "labels=np.concatenate((folder1_labels,folder2_labels,folder3_labels,folder4_labels,folder5_labels,folder6_labels,folder7_labels,folder8_labels,folder9_labels,folder10_labels),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11d74037-3ed1-4cd3-bef7-68a1b0db6ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30010, 28, 28, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cbf6ec2-8ac0-4f88-bd65-af9e63cfec2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30010,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b08687-8b11-4d81-92b6-9409ae6c3992",
   "metadata": {},
   "source": [
    "SPLIT DATA INTO TRAIN AND TEST SETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32bab4ed-d292-4538-9a72-a549e2796fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(images,labels,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac53685-188c-4719-8f7a-55f29cd664d3",
   "metadata": {},
   "source": [
    "BUILD THE NEURAL NETWORK MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc690ef0-29a5-4c66-bf52-675c86f9165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.Sequential([\n",
    "    layers.Conv2D(32,(3,3),activation='relu',input_shape=(28,28,3)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a533ee86-0d32-46ca-986d-972eaf910423",
   "metadata": {},
   "source": [
    "COMPILE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "685a477a-a6a7-4681-83cd-53ac61ad50b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cd144e-f450-4c47-bdbb-599f66d08976",
   "metadata": {},
   "source": [
    "TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6096cb13-c6da-437d-b735-120c46a25869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "751/751 [==============================] - 27s 33ms/step - loss: 0.4365 - accuracy: 0.8605 - val_loss: 0.1193 - val_accuracy: 0.9640\n",
      "Epoch 2/10\n",
      "751/751 [==============================] - 22s 30ms/step - loss: 0.0919 - accuracy: 0.9723 - val_loss: 0.0718 - val_accuracy: 0.9780\n",
      "Epoch 3/10\n",
      "751/751 [==============================] - 33s 44ms/step - loss: 0.0591 - accuracy: 0.9820 - val_loss: 0.0590 - val_accuracy: 0.9810\n",
      "Epoch 4/10\n",
      "751/751 [==============================] - 40s 53ms/step - loss: 0.0451 - accuracy: 0.9860 - val_loss: 0.0546 - val_accuracy: 0.9830\n",
      "Epoch 5/10\n",
      "751/751 [==============================] - 40s 53ms/step - loss: 0.0337 - accuracy: 0.9894 - val_loss: 0.0451 - val_accuracy: 0.9860\n",
      "Epoch 6/10\n",
      "751/751 [==============================] - 40s 53ms/step - loss: 0.0274 - accuracy: 0.9911 - val_loss: 0.0449 - val_accuracy: 0.9857\n",
      "Epoch 7/10\n",
      "751/751 [==============================] - 40s 53ms/step - loss: 0.0259 - accuracy: 0.9919 - val_loss: 0.0618 - val_accuracy: 0.9825\n",
      "Epoch 8/10\n",
      "751/751 [==============================] - 41s 55ms/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.0527 - val_accuracy: 0.9870\n",
      "Epoch 9/10\n",
      "751/751 [==============================] - 40s 53ms/step - loss: 0.0184 - accuracy: 0.9939 - val_loss: 0.0468 - val_accuracy: 0.9870\n",
      "Epoch 10/10\n",
      "751/751 [==============================] - 23s 30ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.0469 - val_accuracy: 0.9870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1fba0fbd6d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842d03a1-77e9-4eee-897a-e838dcaf4755",
   "metadata": {},
   "source": [
    "EVALUATE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fc497ee-04db-4231-84bc-0da25eab6769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 2s 12ms/step - loss: 0.0469 - accuracy: 0.9870\n",
      "Test accuracy: 0.9870043396949768\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457b13f7-78d4-42a5-bba5-cd8b9680ec75",
   "metadata": {},
   "source": [
    "PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3341aa6-f515-4116-911c-dc1d6837d0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Predicted class: 8\n"
     ]
    }
   ],
   "source": [
    "image_to_predict = Image.open(\"C:\\\\Users\\Priyanshul\\\\OneDrive\\\\Desktop\\\\Handwritten\\\\archive\\\\database\\\\8\\\\train_38_00076.png\").resize((28, 28))\n",
    "image_to_predict = np.array(image_to_predict) / 255.0  # Normalize pixel values to range [0, 1]\n",
    "\n",
    "\n",
    "prediction = model.predict(np.expand_dims(image_to_predict, axis=0))\n",
    "\n",
    "\n",
    "predicted_class = np.argmax(prediction)\n",
    "\n",
    "\n",
    "print(\"Predicted class:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18b3faf-bcab-4d80-b62b-930050bf2b20",
   "metadata": {},
   "source": [
    "SAVE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccec1372-1117-42d4-b62a-2c198dceafdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"C:\\\\Users\\\\Priyanshul\\\\OneDrive\\\\Desktop\\\\Handwritten.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
